# -*- coding: utf-8 -*-
"""Почерк тест v4.1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YDnO1kvbwOACsGo3y5NpSr4chEimC8S5
"""

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity,cosine_distances
import pandas as pd
from collections import Counter
import io
import requests
import json
import matplotlib.pyplot as plt
from scipy.stats import mannwhitneyu
from scipy.stats import ttest_ind
from scipy.stats import norm
import seaborn as sns
from tqdm.auto import tqdm
plt.style.use('ggplot')
from sklearn.manifold import TSNE 
import plotly.express as px

def cos_text(
    data_1, # числовые значения первого текста
    data_2, # числовые значения второго текста
    pair_all# множество объединения пар текстов
    ):
#    print(data_column_1,data_column_2)
#    print(pair_all)
    #boot_it=1000
    boot_data = []
    samples_1=[]
    samples_2=[]
#    for pair_b in pair_all:
#      print(data_1[data_1['pair']==pair_b]['between'].values)
#      pr int(data_2.head())
    
    #cos_val=[[1]]
    for pair_b in pair_all:
#      print(pair_b) 
      l_1=data_1[data_1['pair']==pair_b]['between'].values.astype("float")
      if len(l_1)>0:
        val_1=np.median(l_1)
      else:
        val_1=0      
      l_2=data_2[data_2['pair']==pair_b]['between'].values.astype("float")
      if len(l_2)>0:
        val_2=np.median(l_2)
      else:
        val_2=0          
#      print(val_1,val_2)            
      samples_1.append(val_1)   
      samples_2.append(val_2)
    #print(samples_1)
    A=np.array(samples_1)
    B=np.array(samples_2)
    #A_med=statistic(A)
    #B_med=statistic(B)                
#    print(len(A))
#    print(len(B)) 
    cos_val=cosine_similarity(A.reshape(1,-1),B.reshape(1,-1))
    print('cos=',cos_val)
    return cos_val

def get_bootstrap(
    data_column_1, # числовые значения первой выборки
    data_column_2, # числовые значения второй выборки
    boot_it = 1000, # количество бутстрэп-подвыборок
    statistic = np.mean, # интересующая нас статистика
    bootstrap_conf_level = 0.95 # уровень значимости
    ):
    #print(data_column_1,data_column_2)
    boot_len = max([len(data_column_1), len(data_column_2)])
    #print(boot_len)
    boot_data = []
    for i in tqdm(range(boot_it)): # извлекаем подвыборки
        samples_1 = data_column_1.sample(
            boot_len, 
            replace = True # параметр возвращения
        ).values
        samples_2 = data_column_2.sample(
            boot_len, # чтобы сохранить дисперсию, берем такой же размер выборки
            replace = True
        ).values

#        print(samples_1, len(samples_1),boot_len)
#        print(samples_2,len(samples_2),boot_len)
                
        #boot_data.append(statistic(samples_1-samples_2))
        boot_data.append(statistic(samples_1)-statistic(samples_2))
         
    pd_boot_data = pd.DataFrame(boot_data)
        
    left_quant = (1 - bootstrap_conf_level)/2
    right_quant = 1 - (1 - bootstrap_conf_level) / 2
    quants = pd_boot_data.quantile([left_quant, right_quant])
        
    p_1 = norm.cdf(
        x = 0, 
        loc = np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_2 = norm.cdf(
        x = 0, 
        loc = -np.mean(boot_data), 
        scale = np.std(boot_data)
    )
    p_value = min(p_1, p_2) * 2
        
    # Визуализация
 # "  _, _, bars = plt.hist(pd_boot_data[0], bins = 50)
 #   for bar in bars:
 #       if abs(bar.get_x()) <= quants.iloc[0][0] or abs(bar.get_x()) >= quants.iloc[1][0]:
 #           bar.set_facecolor('red')
 #       else: 
 #           bar.set_facecolor('grey')
 #           bar.set_edgecolor('black')
 #   
 #   plt.style.use('ggplot')
 #   plt.vlines(quants,ymin=0,ymax=50,linestyle='--')
 #   plt.xlabel('boot_data')
 #   plt.ylabel('frequency')
 #   plt.title("Histogram of boot_data")
 #   plt.show()
       
    return {"boot_data": boot_data, 
            "quants": quants, 
            "p_value": p_value}

def open_csv_db():
#    url = "https://raw.githubusercontent.com/naturalkind/simple-fake/orm_django/ormapp/media/images/out.csv"
    url ="https://cyber.b24chat.com/media/data_image/out.csv"
    D = requests.get(url).content

    df = pd.read_csv(io.StringIO(D.decode('utf-8')))
    return df
df=open_csv_db()

df = pd.read_csv('/content/out.csv')#.decode('utf-8')))

df.head()

def def_boot(series_1,series_2,pair_b,id_1,id_2,test_list_all):
  print(id_1, id_2, pair_b)      
  test_list=[]
  booted_data=get_bootstrap(series_1, series_2, # числовые значения второй выборки
      boot_it = 1000, # количество бутстрэп-подвыборок
      statistic = np.median, # интересующая нас статистика
      bootstrap_conf_level = 0.95 # уровень значимости
      )
  test_list.append(id_1)
  test_list.append(id_2)
  test_list.append(pair_b)
  test_list.append(booted_data["p_value"])
  test_list_all.append(test_list)
  print('p_value=',booted_data["p_value"])
  return test_list_all

def time_pair(JS,id):
  time_a=[]
  for i in range(len(JS)-1):
    time_JS=[]
    pair=JS[i]['key_name']+JS[i+1]['key_name']
    t11= JS[i]['time_keydown']
#    t12= JS[i]['time_keyup']
#    t1=t12-t11
    t21= JS[i+1]['time_keydown']
#    t22= JS[i+1]['time_keyup']
#    t2=t22-t21
    time_JS.append(id)
    time_JS.append(0)      
    time_JS.append(t21-t11)    
    time_JS.append(pair)
    time_JS.append(len(JS))    
    time_a.append(time_JS)

  return time_a

df.to_csv('df.csv')

"""# Сравнение

"""

id_list=df['id'].unique()
text_all=[0.0,0.0,0.0,0.0,0.0]
for i in range(0,len(id_list)):
  first_t=id_list[i]
  JS=eval(df[df['id']==first_t]['pure_data'][i])    
  time=(time_pair(JS,first_t))
#    print(time)
  text_all=np.vstack([text_all, time])
dataset=pd.DataFrame(text_all[1:],columns=['id',  'time_key', 'between','pair','len_text'])

dataset.head()

pair_un=dataset['pair'].unique()
data_count=dataset.groupby(['id','pair'])['time_key'].count().reset_index()
data_count.to_csv('data_count.csv')
data_vector=dataset.groupby(['pair','id'])['between'].agg(['median','max']).reset_index()

matrice=pd.pivot_table(data_vector,
               index=["id"],
               columns=['pair'],
               values=['median'],aggfunc=np.sum,fill_value=-1).reset_index()

m_col=['id']
for i in range(1,matrice.shape[1]):
  matrice.columns[i][1]
  m_col.append(matrice.columns[i][1])
#m_col

matrice.columns=m_col

matrice.head()

matr=matrice[matrice.columns[1:]]

tsne = TSNE(n_components=2, perplexity=20, random_state=1000) 
projections = tsne.fit_transform(matr) 
fig = px.scatter( projections, x=0, y=1, color=matrice.id, labels={'color': 'id'}  ) 
#    fig = px.scatter( projections, x=0, y=1) 
fig.show()

data_vector.head(50)

"""## Подготовка данных"""

#from pandas.core.groupby import groupby
dataset_median=dataset.groupby(['id',	'pair'])['time_key','between'].median().reset_index()
dataset_median

dataset_median.to_excel('dataset_median_2.xls')

dataset_time=dataset.groupby(['id','pair'])['between'].agg(list).reset_index()
dataset_time

dataset_time.to_csv('dataset_time.csv')

"""## тест гипотез"""

id_list=dataset['id'].unique()
test_list_all=[]
test_list=[]
for id_1 in range(len(id_list)-1):
#for id_1 in range(len(id_list)):  
#for id_1 in range(1,5):    #test_list=[]
  id_first=id_list[id_1]
  for id_2 in range(id_1+1,len(id_list)):
    test_list=[]  
#  for id_2 in range(id_1,len(id_list)):

#  for id_2 in range(id_1+1,5):
#  for id_2 in range(16,29):

    id_second=id_list[id_2]  
#    print(id_1,id_2)
    p1=set(dataset[dataset['id']==id_first]['pair'].values)
#    print(p1)
    p2=set(dataset[dataset['id']==id_second]['pair'].values)
#    print(p2)
    #pair_all=list(p1&p2)#[:100]
    pair_union=list(p1|p2)#[:100]
    data_1=dataset[dataset['id']==id_first][['pair','between']]#.values
    data_2=dataset[dataset['id']==id_second][['pair','between']]#.values
#    print(data_1.head())
    #data_1=dataset_work[(dataset_work['id']==id_first)][['pair','between']]#.values
    #data_2=dataset_work[(dataset_work['id']==id_second)][['pair','between']]#.values              
    text_cos=cos_text(
    data_1, # числовые значения первого текста
    data_2, # числовые значения второго текста
    pair_union# множество объединения пар текстов
    )
    s=list(text_cos)[0][0]
    test_list.append(id_first)
    test_list.append(id_second)
    test_list.append(len(pair_union))
    test_list.append(s)
    test_list_all.append(test_list)

test_list_all

data_cos=pd.DataFrame(test_list_all,columns=['id_1', 'id_2' ,'pair','cos'])
data_cos.to_csv('data_cos.csv')
#data_rez['sig']=data_rez['p-value']/(data_rez['p-value']+0.05)

data_cos.head()

id_list=dataset['id'].unique()

id_list=dataset['id'].unique()
test_list=[]
for id_1 in range(len(id_list)-1):
#for id_1 in range(len(id_list)):  
#for id_1 in range(1,5):
  id_first=id_list[id_1]
  for id_2 in range(id_1+1,len(id_list)):
#  for id_2 in range(id_1,len(id_list)):

#  for id_2 in range(id_1+1,5):
#  for id_2 in range(16,29):

    id_second=id_list[id_2]  
#    print(id_1,id_2)
    p1=set(dataset[dataset['id']==id_first]['pair'].values)
#    print(p1)
    p2=set(dataset[dataset['id']==id_second]['pair'].values)
#    print(p2)
    pair_all=list(p1&p2)#[:100]
    for pair_b in pair_all:
#      print(id_1, id_2, pair_b)         
      series_1=dataset[(dataset['id']==id_first)&(dataset['pair']==pair_b)]['between']#.values
      series_2=dataset[(dataset['id']==id_second)&(dataset['pair']==pair_b)]['between']#.values
      if len(series_1)>3 and len(series_2)>3:                                                     
        test_list=def_boot(series_1.astype("float"),series_2.astype("float"),pair_b,id_first,id_second,test_list)

data_rez=pd.DataFrame(test_list,columns=['id_1', 'id_2' ,'pair','p-value'])
data_rez['sig']=data_rez['p-value']/(data_rez['p-value']+0.05)

data_rez.to_csv('data_rez.csv')



data_rez_e.to_csv('data_rez_i.csv')

id_list=dataset['id'].unique()
test_list=[]
for id_1 in range(len(id_list)-1):
#for id_1 in range(1,5):
  id_first=id_list[id_1]
  for id_2 in range(id_1+1,len(id_list)):
#  for id_2 in range(id_1+1,5):
#  for id_2 in range(16,27):

    id_second=id_list[id_2]  
#    print(id_1,id_2)
    p1=set(dataset[dataset['id']==id_first]['pair'].values)
#    print(p1)
    p2=set(dataset[dataset['id']==id_second]['pair'].values)
#    print(p2)
    pair_all=list(p1&p2)#[:100]
    for pair_b in pair_all:
#      print(id_1, id_2, pair_b)         
      series_1=dataset[(dataset['id']==id_first)&(dataset['pair']==pair_b)]['time_key']#.values
      series_2=dataset[(dataset['id']==id_second)&(dataset['pair']==pair_b)]['time_key']#.values
      if len(series_1)>3 and len(series_2)>3:                                                     
        test_list_key=def_boot(series_1.astype("float"),series_2.astype("float"),pair_b,id_first,id_second,test_list)

time_key_e=pd.DataFrame(test_list,columns=['id_1', 'id_2' ,'pair','p-value'])
time_key_e.to_csv('time_key_i.csv')